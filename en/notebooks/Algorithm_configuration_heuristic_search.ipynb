{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Machine Learning - Group 6 - Algorithm configuration: heuristic search.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZDH3by9XTKeX"
      },
      "source": [
        "#  Heuristic Search\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwyJbxflLARn"
      },
      "source": [
        "#What's a Heuristic?\n",
        "\n",
        "Heuristic is a way to find an approximate solution faster than classic methods can find an exact solution. Heuristic functions take a look at search algorithms. At each step, it ranks alternatives, making decisions based on available informations. Even though they are effective in a lot of cases, heuristic functions are not guarantee to work for every case. \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c1rkEGRzNPx1"
      },
      "source": [
        "#Why do we need heuristics?\n",
        "\n",
        "In the context of machine learning, classic methods of finding a good solution to the algorithm selection and configuration problem are either:\n",
        "- A grid search, which becomes very computationally expensive very quickly with the increase of parameter space.\n",
        "- A random search, which can be faster than a grid search, but with which finding a good solution is completely up to chance.\n",
        "\n",
        "Heuristic approaches come as alternatives to these options which can (consistently) find reasonably good solutions in a relatively short time. The solutions produced will not be necessarily the best, but are at least better than using a default algorithm/configuration."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LuqL1QaFOSz4"
      },
      "source": [
        "#Heuristic Search Techniques in AI\n",
        "\n",
        "Heuristic Search Techniques can be categorized in two groups: \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QxPHFRq0QTpK"
      },
      "source": [
        "## Direct Heuristic Search Techniques in AI\n",
        "\n",
        "Heuristic Search Techniques of this category search the entiry space to find a solution and use an arbitrary ordering of operations. Their viability are low because they use a lot of time or memory. Breadth First Search (BFS) and Depth First Search (DFS) are examples of this group. \n",
        "\n",
        "Other names we can use to classify this group are: Blind Search, Uninformed Search, and Blind Control Strategy.\n",
        "\n",
        "## Weak Heuristic Search Techniques in AI\n",
        "\n",
        "Also called as Informed Search, Heuristic Search, and Heuristic Control Strategy, heuristic functions of this group are effective when applied correctly to the right kind of tasks. For this group, we need extra informations, like domain-specific data, to explore, expand and compute preference among child nodes.\n",
        "\n",
        "Somes examples of heuristic function of this category are: Best-First Search, A* Search, Bidirectional Search, Tabu Search, Beam Search, Simulated Annealing, Hill Climbing and Constraint Satisfaction Problems (CSP)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B3LyHsIXrje-"
      },
      "source": [
        "#Tune-sklearn "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vINlSL-64HRY"
      },
      "source": [
        "Now bringing to the scikit-learn, it provides us two methods out-of-the-box to address hyperparameter tuning: the Grid Search (GridSearchCV) and Random Search (RandomizedSearchCV), both mentioned previously. But, as mentioned, these are respectivelly really time costly and really unrealiable, since they use \"brutal force\" to find the right hyperparameter configurations. To overcome that, we can use Tune-sklearn.\n",
        "\n",
        "Tune-sklearn is a substitute for the Scikit-Learn's model selection module. Using techniques like bayesian optimization, early stopping and distributed execution, it provides a speedup over the Grid Search and Randon Search techniques.\n",
        "\n",
        "Somes vantages of Tune-sklearn are:\n",
        "\n",
        "*   It works really well with scikit-learn: both have a very similar interface, and so you don't need to change a lot of lines in a standard scikit-learn script to use Tune-sklearn.\n",
        "*   It presents Framework support:  tune-it is used primarily for tuning Scikit-Learn models, but it supports other frameworks with Scikit-Learn wrappers, like: Skorch (Pytorch), KerasClassifiers (Keras), and XGBoostClassifiers (XGBoost).\n",
        "*   Scales up: it helps the Ray Tune, library for distributed hyperparameter tuning, to parallelize cross validation on multiple cores in a transparently and efficiently way.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GVcBubU7xPFt"
      },
      "source": [
        "#First Steps\n",
        "\n",
        "At first, we need to install the libraries that we are going to use. In this case, we are going to use the:\n",
        "\n",
        "\n",
        "*   scikit-optimize\n",
        "*   tune_sklearnk\n",
        "*   tune-sklearn \"ray[tune]\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IwFIh0rCMav9",
        "outputId": "f3b3b38a-d25a-40d8-8bbd-b993538ba652",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "!pip install scikit-optimize\n",
        "!pip install tune-sklearn \"ray[tune]\""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting scikit-optimize\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8b/03/be33e89f55866065a02e515c5b319304a801a9f1027a9b311a9b1d1f8dc7/scikit_optimize-0.8.1-py2.py3-none-any.whl (101kB)\n",
            "\r\u001b[K     |███▎                            | 10kB 15.2MB/s eta 0:00:01\r\u001b[K     |██████▌                         | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 30kB 2.2MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 40kB 2.4MB/s eta 0:00:01\r\u001b[K     |████████████████▏               | 51kB 1.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▊         | 71kB 2.4MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 81kB 2.6MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 92kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 102kB 2.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.16.0)\n",
            "Collecting pyaml>=16.9\n",
            "  Downloading https://files.pythonhosted.org/packages/15/c4/1310a054d33abc318426a956e7d6df0df76a6ddfa9c66f6310274fb75d42/pyaml-20.4.0-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy>=0.19.1 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (1.18.5)\n",
            "Requirement already satisfied: scikit-learn>=0.20.0 in /usr/local/lib/python3.6/dist-packages (from scikit-optimize) (0.22.2.post1)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from pyaml>=16.9->scikit-optimize) (3.13)\n",
            "Installing collected packages: pyaml, scikit-optimize\n",
            "Successfully installed pyaml-20.4.0 scikit-optimize-0.8.1\n",
            "\u001b[31mERROR: Could not find a version that satisfies the requirement tune_sklearnk (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for tune_sklearnk\u001b[0m\n",
            "Collecting tune-sklearn\n",
            "  Downloading https://files.pythonhosted.org/packages/4f/aa/4ada108a9528bc82f644a6c467e49d67c26a11103c3ecc9b0d337bb218c3/tune_sklearn-0.1.0-py3-none-any.whl\n",
            "Collecting ray[tune]\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ea/ed/ff896981d4ac684614236f73c1a20cde5f6cb0e2a590c182f62b22706ab4/ray-1.0.0-cp36-cp36m-manylinux1_x86_64.whl (22.9MB)\n",
            "\u001b[K     |████████████████████████████████| 22.9MB 1.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from tune-sklearn) (1.1.2)\n",
            "Collecting parameterized\n",
            "  Downloading https://files.pythonhosted.org/packages/ba/6b/73dfed0ab5299070cf98451af50130989901f50de41fe85d605437a0210f/parameterized-0.7.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from tune-sklearn) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from tune-sklearn) (0.22.2.post1)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from tune-sklearn) (0.8.7)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.6/dist-packages (from tune-sklearn) (1.18.5)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.8.0)\n",
            "Collecting aiohttp-cors\n",
            "  Downloading https://files.pythonhosted.org/packages/13/e7/e436a0c0eb5127d8b491a9b83ecd2391c6ff7dcd5548dfaec2080a2340fd/aiohttp_cors-0.7.0-py3-none-any.whl\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.0.12)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.0.0)\n",
            "Collecting colorful\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/8e/e386e248266952d24d73ed734c2f5513f34d9557032618c8910e605dfaf6/colorful-0.5.4-py2.py3-none-any.whl (201kB)\n",
            "\u001b[K     |████████████████████████████████| 204kB 31.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: protobuf>=3.8.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.12.4)\n",
            "Collecting gpustat\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b4/69/d8c849715171aeabd61af7da080fdc60948b5a396d2422f1f4672e43d008/gpustat-0.6.0.tar.gz (78kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 8.1MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.23.0)\n",
            "Collecting opencensus\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/50/68/4f407bc0980158001c802222fab17e946728aef13f42e5d80d39dfc9ca67/opencensus-0.7.11-py2.py3-none-any.whl (127kB)\n",
            "\u001b[K     |████████████████████████████████| 133kB 39.6MB/s \n",
            "\u001b[?25hCollecting aiohttp\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/78/a6/93acfa8f8b3573c4445ace2f266de62783231923706a4c3ab705e7d43497/aiohttp-3.6.3-cp36-cp36m-manylinux1_x86_64.whl (1.2MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2MB 40.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (7.1.2)\n",
            "Collecting py-spy>=0.2.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8e/a7/ab45c9ee3c4654edda3efbd6b8e2fa4962226718a7e3e3be6e3926bf3617/py_spy-0.3.3-py2.py3-none-manylinux1_x86_64.whl (2.9MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9MB 40.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.6.0)\n",
            "Collecting redis<3.5.0,>=3.3.2\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f0/05/1fc7feedc19c123e7a95cfc9e7892eb6cdd2e5df4e9e8af6384349c1cc3d/redis-3.4.1-py2.py3-none-any.whl (71kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.6MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting aioredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b0/64/1b1612d0a104f21f80eb4c6e1b6075f2e6aba8e228f46f229cfd3fdac859/aioredis-1.3.1-py3-none-any.whl (65kB)\n",
            "\u001b[K     |████████████████████████████████| 71kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: google in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (2.0.3)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (1.32.0)\n",
            "Collecting tensorboardX; extra == \"tune\"\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n",
            "\u001b[K     |████████████████████████████████| 317kB 37.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" and extra == \"tune\" in /usr/local/lib/python3.6/dist-packages (from ray[tune]) (0.7)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->tune-sklearn) (2.8.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->tune-sklearn) (2018.9)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->tune-sklearn) (0.16.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[tune]) (50.3.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.8.0->ray[tune]) (1.15.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.6/dist-packages (from gpustat->ray[tune]) (5.4.8)\n",
            "Collecting blessings>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/03/74/489f85a78247609c6b4f13733cbf3ba0d864b11aa565617b645d6fdf2a4a/blessings-1.7-py3-none-any.whl\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (2020.6.20)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->ray[tune]) (1.24.3)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.6/dist-packages (from opencensus->ray[tune]) (1.16.0)\n",
            "Collecting opencensus-context==0.1.2\n",
            "  Downloading https://files.pythonhosted.org/packages/f1/33/990f1bd9e7ee770fc8d3c154fc24743a96f16a0e49e14e1b7540cc2fdd93/opencensus_context-0.1.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: typing-extensions>=3.6.5; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (3.7.4.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.6/dist-packages (from aiohttp->ray[tune]) (20.2.0)\n",
            "Collecting yarl<1.6.0,>=1.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a0/b4/2cbeaf2c3ea53865d9613b315fe24e78c66acedb1df7e4be4e064c87203b/yarl-1.5.1-cp36-cp36m-manylinux1_x86_64.whl (257kB)\n",
            "\u001b[K     |████████████████████████████████| 266kB 42.9MB/s \n",
            "\u001b[?25hCollecting multidict<5.0,>=4.5\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1a/95/f50352b5366e7d579e8b99631680a9e32e1b22adfa1629a8f23b1d22d5e2/multidict-4.7.6-cp36-cp36m-manylinux1_x86_64.whl (148kB)\n",
            "\u001b[K     |████████████████████████████████| 153kB 34.0MB/s \n",
            "\u001b[?25hCollecting async-timeout<4.0,>=3.0\n",
            "  Downloading https://files.pythonhosted.org/packages/e1/1e/5a4441be21b0726c4464f3f23c8b19628372f606755a9d2e46c187e65ec4/async_timeout-3.0.1-py3-none-any.whl\n",
            "Collecting idna-ssl>=1.0; python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/46/03/07c4894aae38b0de52b52586b24bf189bb83e4ddabfe2e2c8f2419eec6f4/idna-ssl-1.1.0.tar.gz\n",
            "Collecting hiredis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ed/7d/6acf1c8d4f2fb327ff6feec000b4c56a20628fbe966a4c7cd16c0b80343c/hiredis-1.1.0-cp36-cp36m-manylinux2010_x86_64.whl (61kB)\n",
            "\u001b[K     |████████████████████████████████| 61kB 7.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.6/dist-packages (from google->ray[tune]) (4.6.3)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=0.4.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.17.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.6/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (1.52.0)\n",
            "Collecting contextvars; python_version >= \"3.6\" and python_version < \"3.7\"\n",
            "  Downloading https://files.pythonhosted.org/packages/83/96/55b82d9f13763be9d672622e1b8106c85acb83edd7cc2fa5bc67cd9877e9/contextvars-2.4.tar.gz\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.1.1)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3\" in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (4.6)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.6/dist-packages (from google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.2.8)\n",
            "Collecting immutables>=0.9\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/e0/ea6fd4697120327d26773b5a84853f897a68e33d3f9376b00a8ff96e4f63/immutables-0.14-cp36-cp36m-manylinux1_x86_64.whl (98kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 7.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.6/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3\"->google-auth<2.0dev,>=0.4.0->google-api-core<2.0.0,>=1.0.0->opencensus->ray[tune]) (0.4.8)\n",
            "Building wheels for collected packages: gpustat, idna-ssl, contextvars\n",
            "  Building wheel for gpustat (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for gpustat: filename=gpustat-0.6.0-cp36-none-any.whl size=12622 sha256=c2bd7ddfcd8cf9e9dc79708bee833b9c553fba8535334633b6a44946ee71929d\n",
            "  Stored in directory: /root/.cache/pip/wheels/48/b4/d5/fb5b7f1d040f2ff20687e3bad6867d63155dbde5a7c10f4293\n",
            "  Building wheel for idna-ssl (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for idna-ssl: filename=idna_ssl-1.1.0-cp36-none-any.whl size=3161 sha256=2c551f3f74a9fb20c9ab192610bad877afca074f2ef6c257924da8d006248a43\n",
            "  Stored in directory: /root/.cache/pip/wheels/d3/00/b3/32d613e19e08a739751dd6bf998cfed277728f8b2127ad4eb7\n",
            "  Building wheel for contextvars (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for contextvars: filename=contextvars-2.4-cp36-none-any.whl size=7666 sha256=6e007e8662d740b3693111eb3220df377a6845e1cc75e7d37a4e80c6483da698\n",
            "  Stored in directory: /root/.cache/pip/wheels/a5/7d/68/1ebae2668bda2228686e3c1cf16f2c2384cea6e9334ad5f6de\n",
            "Successfully built gpustat idna-ssl contextvars\n",
            "Installing collected packages: multidict, yarl, async-timeout, idna-ssl, aiohttp, aiohttp-cors, colorful, blessings, gpustat, immutables, contextvars, opencensus-context, opencensus, py-spy, redis, colorama, hiredis, aioredis, tensorboardX, ray, parameterized, tune-sklearn\n",
            "Successfully installed aiohttp-3.6.3 aiohttp-cors-0.7.0 aioredis-1.3.1 async-timeout-3.0.1 blessings-1.7 colorama-0.4.4 colorful-0.5.4 contextvars-2.4 gpustat-0.6.0 hiredis-1.1.0 idna-ssl-1.1.0 immutables-0.14 multidict-4.7.6 opencensus-0.7.11 opencensus-context-0.1.2 parameterized-0.7.4 py-spy-0.3.3 ray-1.0.0 redis-3.4.1 tensorboardX-2.1 tune-sklearn-0.1.0 yarl-1.5.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "16U2UwOVzpyr"
      },
      "source": [
        "#TuneGridSearchCV Example\n",
        "\n",
        "We are going to start by doing an example of a Tune Grid Search.\n",
        "\n",
        "First, we are going to do somes imports that we are going to need during the process.\n",
        "\n",
        "We are going to use a custom \"dummy\" dataset and SGDClassifier to classify the data. This classifier provides us the partial_fit API, which allows us to stop fitting data for a certain hyperparameter configuration when it is no longer beneficial. If the estimator does not support early stopping, we fall back to a parallel grid search."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z51sA-DrH82T"
      },
      "source": [
        "import numpy as np\n",
        "from tune_sklearn import TuneSearchCV\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "from tune_sklearn import TuneGridSearchCV"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oM0w-XCO3Esq"
      },
      "source": [
        "As you can see below, we do the setup in the same way we would do for Scikit-Learn."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Er5AM_YcTw1Y"
      },
      "source": [
        "# Set training and validation sets\n",
        "X, y = make_classification(n_samples=11000, n_features=1000, n_informative=50, \n",
        "                           n_redundant=0, n_classes=10, class_sep=2.5)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000)\n",
        "\n",
        "# Example parameters to tune from SGDClassifier\n",
        "parameters = {\n",
        "   'alpha': [1e-4, 1e-1, 1],\n",
        "   'epsilon':[0.01, 0.1]\n",
        "}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSUHW-3U3UZX"
      },
      "source": [
        "Now, we are going to try fitting a model."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v_UENQ6b3wzH"
      },
      "source": [
        "Some differences that you will notice:\n",
        "\n",
        "\n",
        "\n",
        "*   a new *early_stopping* variable: it says when to stop early - it uses the MedianStoppingRule by default, but there is a list of possilities that you can see in [Tune’s documentation](https://docs.ray.io/en/latest/tune/api_docs/schedulers.html);\n",
        "*   a specification of *max_iters* parameter: it's the maximun number of iterations that a set o Hyperparameters can run; if the process is stopped early, it may have less iteration. \n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZSrlj8lUO_1",
        "outputId": "43c3acb6-b519-4c31-8a4a-2f046ece031e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "tune_search = TuneGridSearchCV(\n",
        "    SGDClassifier(),\n",
        "    parameters,\n",
        "    early_stopping=True,\n",
        "    max_iters=10\n",
        ")\n",
        "\n",
        "import time # Just to compare fit times\n",
        "\n",
        "start = time.time()\n",
        "tune_search.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "print(\"Tune Fit Time:\", end - start)\n",
        "\n",
        "pred = tune_search.predict(X_test)\n",
        "accuracy = np.count_nonzero(np.array(pred) == np.array(y_test)) / len(pred)\n",
        "print(\"Tune Accuracy:\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Tune Fit Time: 41.78004288673401\n",
            "Tune Accuracy: 0.878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Xke5Rcr5Quf"
      },
      "source": [
        "To do a comparation, below we have an equivalete to the code we run before using GridSearchCV. Pay attention to the results and the difference between the running times."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wJQ4u4dbU-pt",
        "outputId": "e83b408d-13be-4673-b053-b02518016421",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "# n_jobs=-1 enables use of all cores like Tune does\n",
        "sklearn_search = GridSearchCV(\n",
        "   SGDClassifier(),\n",
        "   parameters,\n",
        "   n_jobs=-1\n",
        ")\n",
        "\n",
        "start = time.time()\n",
        "sklearn_search.fit(X_train, y_train)\n",
        "end = time.time()\n",
        "print(\"Sklearn Fit Time:\", end - start)\n",
        "pred = sklearn_search.predict(X_test)\n",
        "accuracy = np.count_nonzero(np.array(pred) == np.array(y_test)) / len(pred)\n",
        "print(\"Sklearn Accuracy:\", accuracy)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Sklearn Fit Time: 122.666175365448\n",
            "Sklearn Accuracy: 0.878\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uYaV-Euu5wC1"
      },
      "source": [
        "#TuneSearchCV Bayesian Optimization Example\n",
        "\n",
        "TuneSearchCV is an interface that allow us to sample from distributions of hyperparameters. It also enables to use Bayesian optimization over the distribution with an addition of a few lines.\n",
        "\n",
        "Bayesian optimization is an approach to optimizing objective functions that take a long time to evaluate. Its strategy is to treat the objective function as a random function and model an a priori probability distribution after it, since the real function is unknown. It has been used in a lot of areas, such as: computer graphics and visual design, architecture configuration in deep learning, automatic algorithm configuration and others."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOrqIpVW80xs"
      },
      "source": [
        "To run the code below, we need to install the library \"scikit-optimize\", which we've already done.\n",
        "\n",
        "In this example, we will continue to use the a \"dummy\" dataset and SGDClassifier as a classifier."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yNww2y9vVmq6",
        "outputId": "df700f30-726d-430a-ece7-7d96e9c4f726",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "from tune_sklearn import TuneSearchCV\n",
        "\n",
        "# Other imports\n",
        "import scipy\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "\n",
        "# Set training and validation sets\n",
        "X, y = make_classification(n_samples=11000, n_features=1000, n_informative=50, \n",
        "                           n_redundant=0, n_classes=10, class_sep=2.5)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=1000)\n",
        "\n",
        "# Example parameter distributions to tune from SGDClassifier\n",
        "# Note the use of tuples instead if Bayesian optimization is desired\n",
        "param_dists = {\n",
        "   'alpha': (1e-4, 1e-1),\n",
        "   'epsilon': (1e-2, 1e-1)\n",
        "}\n",
        "\n",
        "tune_search = TuneSearchCV(SGDClassifier(),\n",
        "   param_distributions=param_dists,\n",
        "   n_trials=2,\n",
        "   early_stopping=True,\n",
        "   max_iters=10,\n",
        "   search_optimization=\"bayesian\"\n",
        ")\n",
        "\n",
        "tune_search.fit(X_train, y_train)\n",
        "print(tune_search.best_params_) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "{'alpha': 0.0870109160675465, 'epsilon': 0.061442965886015694}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jtZBUGgg-BAy"
      },
      "source": [
        "As you can see, it’s pretty simple to use tune-sklearn and integrate it to an existing code. But, as any heuristic method, it will not suffice for every application, since it doesn't always finds the best solutions.\n",
        "\n",
        "If you want to know more about tune-sklearn, here are a few links that might be useful:\n",
        "\n",
        "*   [Tune-sklearn documentation](https://github.com/ray-project/tune-sklearn)\n",
        "\n",
        "*   [ Scikit-Learn Pipelines with tune-sklearn](https://github.com/ray-project/tune-sklearn/blob/master/examples/sklearn_pipeline.py)\n",
        "\n"
      ]
    }
  ]
}